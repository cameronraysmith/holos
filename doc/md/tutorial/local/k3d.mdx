import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Try Holos Locally

Learn how to configure and deploy the Holos reference platform to your local
host with k3d.

---

This guide assumes commands are run from your local host.  Capitalized terms
have specific definitions described in the [Glossary](/docs/glossary).

## What you'll need {#Requirements}

You'll need the following tools installed on your local host to complete this guide.

 1. [holos](/docs/tutorial/install) - to build the platform.
 2. [k3d](https://k3d.io/#installation) - to provide an api server.
 3. [Docker](https://docs.docker.com/get-docker/) - to use k3d.
 4. [kubectl](https://kubernetes.io/docs/tasks/tools/) - to interact with the Kubernetes cluster.
 5. [helm](https://helm.sh/docs/intro/install/) - to render Holos components that integrate vendor provided Helm charts.
 6. [mkcert](https://github.com/FiloSottile/mkcert?tab=readme-ov-file#installation) - for local trusted certificates.
 7. [jq](https://jqlang.github.io/jq/download/) - to manipulate json output.

## Outcome

At the end of this guide you'll have built a development platform that provides
Zero Trust security by holistically integrating off-the-shelf components.

 1. ArgoCD to review and apply platform configuration changes.
 2. Istio service mesh with mTLS encryption.
 3. ZITADEL to provide single sign-on identity tokens with multi factor authentication.

The platform running on your local host will configure Istio to authenticate and
authorize requests using an oidc id token issued by ZITADEL _before_ the request
ever reaches ArgoCD.

:::tip

With Holos, developers don't need to write authentication or authorization logic
for many common use cases.

:::

The platform provides single sign-on and role based access control for all
services running on the platform.

The `k3d` platform is derived from the Holos reference platform.  THe `k3d`
platform is intended to provide a smooth on-ramp to evaluate Holos.

 1. Holos provides a unified configuration model purpose built to integrate
 unmodified Helm charts, Kustomize bases, or any manifest provided by a software
 vendor.
 2. Holos eliminates the need to template yaml, a common source of errors.
 3. Holos platforms are composable, scaling down to your laptop and up to
 multiple clusters across multiple regions.
 4. The unified configuration model is well suited to provide a Zero Trust
 security model.

# Get Started

Let's get started building a Holos platform locally.

## Register with Holos

The first step is to register an account with the Holos web service.
Registration is necessary to save platform configuration values using a simple
web form and to explore how Holos implements Zero Trust and single sign on.

```bash
holos register user
```

## Create the Platform {#Create-Platform}

A platform resource in the Holos web service is necessary to store the web form
used to submit top level configuration values.

Create the platform resource using the command line tool which makes an rpc call
to the web service.

```bash
holos create platform --name k3d --display-name "Try Holos Locally"
```

## Generate the Platform {#Generate-Platform}

Holos operates almost exclusively against local files stored in version control.
The Holos web service is used primarily to store the Platform Model, but is not
used day-to-day when making configuration changes or deploying applications.

In an empty `holos-k3d` directory, generate the local files necessary to build
the platform.

First, [fork the holos-k3d](https://github.com/holos-run/holos-k3d/fork)
repository to get started.  Once forked, clone it locally.  Replace the URL with
your fork.

```bash
git clone https://github.com/holos-run/holos-k3d.git
cd holos-k3d
```

Then generate the platform code in root of the new repository:

```bash
holos generate platform k3d
```

Commit the generated platform config to the repository:

```bash
git add .
git commit -m "holos generate platform k3d - $(holos --version)"
```

## Push the Git repository

This tutorial deploys ArgoCD, which needs to sync configuration from a Git
repository.  Push the repository you created to a new blank repository.  Note
that holos is designed to never store secrets in version control.

```bash
git push origin HEAD:main
```

## Push the Platform Form

Each Holos platform has a Platform Form used to submit top level, platform-wide
configuration values.  The purpose of the form is to validate configuration
values and simplify complicated configurations and integrations.

Push the Platform Form to the web service to publish it and make it accessible
through a web browser.

```bash
holos push platform form .
```

:::important

Once pushed, visit the URL that is printed back to see the form on the web.

:::

You should see a form with default values filled in that looks like:

![Platform Form Default Values](./form-pushed.png)

## Submit the Platform Model

Before we build the platform we need to configure role based access control to
only allow our own identity to access protected services.  In the local k3d
platform, this is accomplished by validating the OIDC id token subject claim.

### RBAC

Provide the value of the `sub` subject claim of your identity to ensure only you
have administrative access to ArgoCD.

Obtain the value using:

```bash
holos login --print-claims | jq -r .sub
```

The last line printed should be a positive whole number like `99999999999999`.
Copy this in to the form field and submit the form.

### GitOps

For the ArgoCD Git repository URL form field, enter the url of your Github fork
where you pushed your local `holos-k3d` repository.

## Pull the Platform Model

Once the form values have been submitted, the data needs to be pulled into the
Git repository so `holos` can operate locally.

The Platform Model is the JSON representation of the Platform Form values.
Holos provides the Platform Model to CUE to render the platform into plain YAML.

Pull the Platform Model to your local host to render the platform.

```bash
holos pull platform model .
```

The `platform.config.json` contains the Platform Model and is intended to be
committed to version control.

```bash
git add platform.config.json
git commit -m "Add platform model"
```

## Render the Platform

With the `platform.config.json` file and generated files in place, `holos` has
everything necessary to build the complete platform.

Rendering a platform is a process of iterating over each platform component and
rendering the component into plain YAML manifests to be sent directly to the API
server.

```bash
holos render platform ./platform
```

This command writes fully rendered manifest files to the `deploy/` directory.

Commit the rendered platform manifests so they can be applied via GitOps later
on.

```bash
git add deploy
git commit -m "holos render platform ./platform"
```

### Rendering {#Rendering}

Holos uses the Kubernetes resource model to manage configuration.  The `holos`
command line interface (cli) is the primary method you'll use to manage your
platform.  Holos uses CUE to provide a unified configuration model of the
platform which is built from components packaged with Helm, Kustomize, CUE, or
any tool that can produce Kubernetes resources as output.  This process can be
thought of as a yaml **rendering pipeline**.

Each component in a platform defines a rendering pipeline shown in Figure 2 to
produce Kubernetes api resources

```mermaid
---
title: Figure 2 - Render Pipeline
---
graph LR
    PS[<a href="/docs/api/core/v1alpha2#PlatformSpec">PlatformSpec</a>]
    BP[<a href="/docs/api/core/v1alpha2#BuildPlan">BuildPlan</a>]
    HC[<a href="/docs/api/core/v1alpha2#HolosComponent">HolosComponent</a>]

    H[<a href="/docs/api/core/v1alpha2#HelmChart">HelmChart</a>]
    K[<a href="/docs/api/core/v1alpha2#KustomizeBuild">KustomizeBuild</a>]
    O[<a href="/docs/api/core/v1alpha2#KubernetesObjects">KubernetesObjects</a>]

    P[<a href="/docs/api/core/v1alpha2#Kustomize">Kustomize</a>]
    Y[Kubernetes <br>Resources]
    G[GitOps <br>Resource]

    C[Kube API Server]

    PS --> BP --> HC
    HC --> H --> P
    HC --> K --> P
    HC --> O --> P

    P --> Y --> C
    P --> G --> C
```

The `holos` cli can be thought of as executing a data pipeline.  The Platform
Model is the top level input to the pipeline and specifies the ways your
platform varies from other organizations.  The `holos` cli takes the Platform
Model as input and executes a series of steps to produce the platform
configuration.  The platform configuration output of `holos` are full
Kubernetes API resources, suitable for application to a cluster with `kubectl
apply -f`, or GitOps tools such as ArgoCD or Flux.

## Create the Workload Cluster

The Workload Cluster is where your applications and services will be deployed.
In production this is usually an EKS, GKE, or AKS cluster.

:::tip

Holos supports any compliant Kubernetes cluster and was developed and tested on
GKE, EKS, Talos, and Kubeadm clusters.

:::

<Tabs>
  <TabItem value="evaluate" label="Evaluate" default>
  Use this command when evaluating Holos.

  ```bash
  k3d cluster create workload \
    --port "443:443@loadbalancer" \
    --k3s-arg "--disable=traefik@server:0"
  ```
  </TabItem>
  <TabItem value="develop" label="Develop" default>
  Use this command when developing Holos.

  ```bash
  k3d registry create registry.holos.localhost --port 5100
  ```

  ```bash
  k3d cluster create workload \
    --registry-use k3d-registry.holos.localhost:5100 \
    --port "443:443@loadbalancer" \
    --k3s-arg "--disable=traefik@server:0"
  ```
  </TabItem>
</Tabs>

Traefik is disabled because Istio provides the same functionality.

## Local CA

Create and apply the `local-ca` Secret containing the CA private key. This
Secret is necessary to issue certificates trusted by your browser when using the
local k3d platform.

```bash
bash ./scripts/local-ca
```

:::note

Admin access is necessary for `mkcert` to install the newly generated CA cert
into your local host's trust store.

:::

## DNS Setup

Configure your localhost to resolve `*.holos.localhost` to your loopback
interface.  This is necessary for your browser requests to reach the k3d
workload cluster.

<Tabs>
  <TabItem value="macos" label="macOS" default>
    ```bash
    brew install dnsmasq
    ```

    ```bash
    cat <<EOF >"$(brew --prefix)/etc/dnsmasq.d/holos.localhost.conf"
    # Refer to https://holos.run/docs/tutorial/local/k3d/
    address=/holos.localhost/127.0.0.1
    EOF
    ```

    ```bash
    if [[ -r /Library/LaunchDaemons/homebrew.mxcl.dnsmasq.plist ]]; then
      echo "dnsmasq already configured"
    else
      sudo cp "$(brew list dnsmasq | grep 'dnsmasq.plist$')" \
        /Library/LaunchDaemons/homebrew.mxcl.dnsmasq.plist
      sudo launchctl unload /Library/LaunchDaemons/homebrew.mxcl.dnsmasq.plist
      sudo launchctl load /Library/LaunchDaemons/homebrew.mxcl.dnsmasq.plist
      dscacheutil -flushcache
      echo "dnsmasq configured"
    fi
    ```

    ```bash
    sudo mkdir -p /etc/resolver
    sudo tee /etc/resolver/holos.localhost <<EOF
    domain holos.localhost
    nameserver 127.0.0.1
    EOF
    sudo killall -HUP mDNSResponder
    ```
  </TabItem>
  <TabItem value="linux" label="Linux">
    [NSS-myhostname](http://man7.org/linux/man-pages/man8/nss-myhostname.8.html)
    ships with many Linux distributions and should resolve *.localhost
    automatically to 127.0.0.1.

    Otherwise it is installable with:

    ```bash
    sudo apt install libnss-myhostname
    ```
  </TabItem>
  <TabItem value="windows" label="Windows">
    Ensure the loopback interface has at least the following names in `C:\windows\system32\drivers\etc\hosts`

		```
    127.0.0.1 httpbin.holos.localhost argocd.holos.localhost app.holos.localhost
		```
  </TabItem>
</Tabs>

## Apply the Platform Components

Use `kubectl` to apply each platform component.  In production, it's common to
fully automate this process with ArgoCD, but we use `kubectl` in development
and exploration contexts to the same effect.

### Namespaces

```bash
kubectl apply --server-side=true -f ./deploy/clusters/workload/components/namespaces
```

### Custom Resource Definitions

Services are exposed with standard `HTTPRoute` resources from the Gateway API.

```bash
kubectl apply --server-side=true -f ./deploy/clusters/workload/components/gateway-api
kubectl apply --server-side=true -f ./deploy/clusters/workload/components/istio-base
kubectl apply --server-side=true -f ./deploy/clusters/workload/components/argo-crds
```

### Cert Manager

Apply the cert-manager controller:

```bash
kubectl apply --server-side=true -f ./deploy/clusters/workload/components/cert-manager
```

Apply the ClusterIssuer which issues Certificate resources using the local
certificate authority.

```bash
kubectl apply --server-side=true -f deploy/clusters/workload/components/local-ca
kubectl apply --server-side=true -f deploy/clusters/workload/components/certificates
```

:::note

If you get a `no endpoints available for service "cert-manager-webhook"` Error
from server, retry this command.  The `cert-manager` Deployment may still be
starting up.

:::


### Istio

```bash
kubectl apply --server-side=true -f ./deploy/clusters/workload/components/istio-cni
kubectl apply --server-side=true -f ./deploy/clusters/workload/components/istiod
kubectl apply --server-side=true -f ./deploy/clusters/workload/components/gateway
```

Verify the Gateway is programmed and the listeners have been accepted:

```bash
kubectl get -n istio-gateways gateway default -o json \
  | jq -r '.status.conditions[].message'
```

Resource programmed indicates the Gateway is ready.

```txt
Resource accepted
Resource programmed, assigned to service(s) default-istio.istio-gateways.svc.cluster.local:443
```

If you see `Failed to assign` then the Gateway pods are likely still starting
up.  Check them with `kubectl get pods -n istio-gateways`.

```
Resource accepted
Failed to assign to any requested addresses: no instances found for hostname "default-istio.istio-gateways.svc.cluster.local"
```

### httpbin

httpbin is a simple backend service useful for end-to-end testing.

```bash
kubectl apply --server-side=true -f deploy/clusters/workload/components/httpbin-backend
kubectl apply --server-side=true -f deploy/clusters/workload/components/httpbin-routes
```

:::important

Browse to [https://httpbin.holos.localhost/](https://httpbin.holos.localhost/)
to verify end to end connectivity.

:::

### Cookie Secret

Generate a random cookie encryption Secret and apply.

```bash
LC_ALL=C tr -dc A-Za-z0-9 </dev/urandom \
  | head -c 32 \
  | kubectl create secret generic "authproxy" \
    --from-file=cookiesecret=/dev/stdin \
    --dry-run=client -o yaml \
  | kubectl apply -n istio-gateways -f-
```
:::tip

The Holos reference platform uses an ExternalSecret to automatically sync this
Secret from your SecretStore.

:::


### Auth Proxy

The auth proxy is responsible for authenticating web browser requests.  The auth
proxy provides a standard oidc id token to all services integrated with the
mesh.

```bash
kubectl apply --server-side=true -f deploy/clusters/workload/components/authproxy
kubectl apply --server-side=true -f deploy/clusters/workload/components/authroutes
```

:::important

Verify authentication is working by visiting
[https://httpbin.holos.localhost/holos/authproxy](https://httpbin.holos.localhost/holos/authproxy).
Expect a simple `Authenticated` response.

:::

:::note

Istio will respond with `no healthy upstream` until the pod becomes ready.
Check on the progress with `kubectl describe pod --namespace holos-system
--selector app.kubernetes.io/instance=httpbin`.

:::

Once authenticated, visit
[https://httpbin.holos.localhost/holos/authproxy/userinfo](https://httpbin.holos.localhost/holos/authproxy/userinfo)
which returns a subset of claims from your id token:

```json
{
  "user": "275552236589843464",
  "email": "demo@holos.run",
  "preferredUsername": "demo"
}
```

### Auth Policy

Configure authorization policies using the claims provided in the authenticated
id token.

```bash
kubectl apply --server-side=true -f deploy/clusters/workload/components/authpolicy
```

:::important

Requests to `https://httpbin.holos.localhost` are protected by
AuthorizationPolicy platform resources after applying this component.

:::

### Zero Trust

A basic Zero Trust security model is now in place.  Verify authentication is
working by browsing to
[https://httpbin.holos.localhost/dump/request](https://httpbin.holos.localhost/dump/request).

:::note

Istio make take a few seconds to program the Gateway with the
AuthorizationPolicy resources.

:::

:::tip

Note the `x-oidc-id-token` header is not sent by your browser but is received
by the backend service.  This design reduces the risk of exposing id tokens.
Requests over the internet are also smaller and more reliable because large id
tokens with may claims are confined to the cluster.

:::

Verify unauthenticated requests are blocked:

```bash
curl -I https://httpbin.holos.localhost/dump/request
```

You should get back a 302 response that redirects the request to the identity
provider to authenticate.

Verify authenticated requests are allowed:

```bash
curl -H x-oidc-id-token:$(holos token) https://httpbin.holos.localhost/dump/request
```

Expect a response from the backend httpbin service with the id token header the
platform authenticated and authorized.

:::tip

Note how the platform secures both web browser and command line api access to
the backend httpbin service.  httpbin itself has no authentication or
authorization functionality.

:::

### ArgoCD

ArgoCD automatically applies resources defined in Git similar to how this guide
uses `kubectl apply`.

Apply controller deployments and supporting resources.

```bash
kubectl apply --server-side=true -f ./deploy/clusters/workload/components/argo-cd
kubectl apply --server-side=true -f ./deploy/clusters/workload/components/argo-authpolicy
kubectl apply --server-side=true -f ./deploy/clusters/workload/components/argo-routes
```

Verify all Pods are running and all containers are ready.

```bash
kubectl get pods -n argocd
```

```txt
NAME                                                READY   STATUS      RESTARTS   AGE
argocd-application-controller-0                     1/1     Running     0          10s
argocd-applicationset-controller-578db65fcd-lnn76   1/1     Running     0          10s
argocd-notifications-controller-67c856dbb7-12stk    1/1     Running     0          10s
argocd-redis-698f57d9b9-v4kqs                       1/1     Running     0          10s
argocd-redis-secret-init-z5zg8                      0/1     Completed   0          10s
argocd-repo-server-69f78dfb8-f6pb7                  1/1     Running     0          10s
argocd-server-58f7f4466d-db5fv                      2/2     Running     0          10s
```

Browse to [https://argocd.holos.localhost/](https://argocd.holos.localhost/) and
verify you get the ArgoCD login page.

![ArgoCD Login Page](./argocd-login.png)

:::note

Both the platform layer and the ArgoCD application layer performs authentication
and authorization using the same identity provider.  Note how the Zero Trust
model provides an additional layer of security without friction.

:::

Login using the SSO button and verify you get to the Applications page.

![ArgoCD Applications](./argocd-apps.png)

### ArgoCD Applications

Apply the Application resources for all of the Holos components that compose the
platform.  The Application resources provide drift detection and optional
automatic reconciliation of platform components.

```bash
kubectl apply --server-side=true -f deploy/clusters/workload/gitops
```

Browse to or refresh [https://argocd.holos.localhost/applications](https://argocd.holos.localhost/applications).

![ArgoCD Holos Components](./argocd-apps-2.png)

:::important

If you do not see any applications after refreshing the page ensure the `sub`
value in the Platform Model (`platform.config.json`) is correct and matches
`holos login --print-claims`.

:::

### Sync Applications

Navigate to the [namespaces Application](https://argocd.holos.localhost/applications/argocd/namespaces).

![ArgoCD Out of Sync](./argocd-out-of-sync.png)

Review the differences between the live platform and the git configuration.

![ArgoCD Diff](./argocd-diff.png)

Sync the application to reconcile the differences.

![ArgoCD Sync](./argocd-sync.png)

The Holos components should report Sync OK.

![ArgoCD Sync OK](./argocd-sync-ok.png)

:::tip

Automatic reconciliation is turned off by default.

:::

Optionally enable automatic reconciliation by adding `spec.syncPolicy.automated:
{}` to the `#Argo` definition.

Add the following to `buildplan.site.cue` to avoid `holos generate platform k3d`
writing over the customization.

:::tip

CUE merges definitions located in multiple files.  This feature is used to
customize the platform.

:::

```bash
cat <<EOF > buildplan.site.cue
package holos
// Enable automated sync of platform components.
#Argo: Application: spec: syncPolicy: automated: {}
EOF
```

Re-render the platform.

```bash
holos render platform ./platform
```

Add and commit the changes.

```bash
git add .
git commit -m 'enable argocd automatic sync'
git push origin HEAD
```

Apply the new changes.

```bash
kubectl apply --server-side=true -f deploy/clusters/workload/gitops
```

Automatic reconciliation is enabled for all platform components.

![ArgoCD Automatic Sync OK](./argocd-auto-sync-ok.png)

## Review the Platform Manifests {#Review}

:::tip

This section is optional, included to provide insight into how Holos uses CUE
and Helm to unify and render the platform configuration.

:::

Take a moment to review the manifests `holos` rendered to build the platform.

### ArgoCD Application

Note the Git URL you entered into the Platform Form is used to derive the ArgoCD
`Application` resource from the Platform Model.

```yaml
# deploy/clusters/workload/gitops/namespaces.application.gen.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: namespaces
  namespace: argocd
spec:
  destination:
    server: https://kubernetes.default.svc
  project: default
  source:
    # highlight-next-line
    path: /deploy/clusters/workload/components/namespaces
    # highlight-next-line
    repoURL: https://github.com/holos-run/holos-k3d
    # highlight-next-line
    targetRevision: HEAD
```

One ArgoCD `Application` resource is produced for each Holos component by
default.  Note the `cert-manger` component renders the output using Helm.
Holos unifies the Application resource using CUE.  The CUE definition which
produces the rendered output is defined in `buildplan.cue` around line 222.

:::tip

Note how CUE does not use error-prone text templates, the language is well
specified and typed which reduces errors when unifying the configuration with
the Platform Model in the following `#Argo` definition.

:::

```cue
// buildplan.cue

// #Argo represents an argocd Application resource for each component, written
// using the #HolosComponent.deployFiles field.
#Argo: {
	ComponentName: string

	Application: app.#Application & {
		metadata: name:      ComponentName
		metadata: namespace: "argocd"
		spec: {
			destination: server: "https://kubernetes.default.svc"
			project: "default"
			source: {
        // highlight-next-line
				path:           "\(_Platform.Model.argocd.deployRoot)/deploy/clusters/\(_ClusterName)/components/\(ComponentName)"
        // highlight-next-line
				repoURL:        _Platform.Model.argocd.repoURL
        // highlight-next-line
				targetRevision: _Platform.Model.argocd.targetRevision
			}
		}
	}

	// deployFiles represents the output files to write along side the component.
	deployFiles: "clusters/\(_ClusterName)/gitops/\(ComponentName).application.gen.yaml": yaml.Marshal(Application)
}
```

### Helm Chart

Holos uses CUE to safely integrate the unmodified upstream `cert-manager` Helm
chart.

:::tip

Holos fully supports your existing Helm charts.  Consider leveraging `holos` as
an safer alternative to umbrella charts.

:::

```cue
// components/cert-manager/cert-manager.cue
package holos

// Produce a helm chart build plan.
(#Helm & Chart).Output

let Chart = {
	Name:      "cert-manager"
	Version:   "1.14.5"
	Namespace: "cert-manager"

	Repo: name: "jetstack"
	Repo: url:  "https://charts.jetstack.io"

  // highlight-next-line
	Values: {
		installCRDs: true
		startupapicheck: enabled: false
		// Must not use kube-system on gke autopilot.  GKE Warden blocks access.
    // highlight-next-line
		global: leaderElection: namespace: Namespace

		// https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-resource-requests#min-max-requests
		resources: requests: {
			cpu:                 "250m"
			memory:              "512Mi"
			"ephemeral-storage": "100Mi"
		}
    // highlight-next-line
		webhook: resources:        Values.resources
    // highlight-next-line
		cainjector: resources:     Values.resources
    // highlight-next-line
		startupapicheck: resource: Values.resources

		// https://cloud.google.com/kubernetes-engine/docs/how-to/autopilot-spot-pods
		nodeSelector: {
			"kubernetes.io/os": "linux"
			if _ClusterName == "management" {
				"cloud.google.com/gke-spot": "true"
			}
		}
		webhook: nodeSelector:         Values.nodeSelector
		cainjector: nodeSelector:      Values.nodeSelector
		startupapicheck: nodeSelector: Values.nodeSelector
	}
}
```

## Summary

In this guide, you built a software development platform which:

1. Configures a Service Mesh with mTLS encryption between services.
2. Configures authentication and authorization of users and developers.
3. Protects a backend service (httpbin) without making any backend code changes.
4. Leverages ArgoCD to automatically deploy configuration and applications.
